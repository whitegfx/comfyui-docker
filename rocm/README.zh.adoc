# 基于 AMD GPU + ROCm 运行 ComfyUI

image:https://github.com/YanWenKun/ComfyUI-Docker/actions/workflows/build-rocm.yml/badge.svg["GitHub Workflow Status",link="https://github.com/YanWenKun/ComfyUI-Docker/actions/workflows/build-rocm.yml"]

https://hub.docker.com/r/yanwk/comfyui-boot/tags?name=rocm[在 <Docker Hub> 上查看]

## 注意：需要自行构建镜像

由于 ROCm PyTorch 太大， GitHub Actions 总是报错“存储空间不足”，导致无法利用 GitHub 自动构建发布镜像，所以不再提供成品镜像。用户运行前需要先构建镜像（基本就是下载，加上少量编译）。

如将来 AMD 缩减 PyTorch 包大小，会将再次启用自动构建。

## 准备工作

* 确保 Linux 宿主机上正确安装了
https://rocm.docs.amd.com/projects/radeon/en/latest/docs/install/native_linux/install-radeon.html[Radeon software for Linux with ROCm]。

## 构建并运行

需要根据 GPU 添加如下环境变量（感谢
https://github.com/YanWenKun/ComfyUI-Docker/pull/67[nhtua]
的 PR）：

- RDNA 及 RDNA 2 : `-e HSA_OVERRIDE_GFX_VERSION=10.3.0 \`
- RDNA 3 :  `-e HSA_OVERRIDE_GFX_VERSION=11.0.0 \`
- APU／集显 : `-e HIP_VISIBLE_DEVICES=0 \`


.使用 Docker
[source,sh]
----
git clone https://github.com/YanWenKun/ComfyUI-Docker.git

cd ComfyUI-Docker/rocm

docker build . -t yanwk/comfyui-boot:rocm

mkdir -p storage

docker run -it --rm \
  --name comfyui-rocm \
  --device=/dev/kfd --device=/dev/dri \
  --group-add=video --ipc=host --cap-add=SYS_PTRACE \
  --security-opt seccomp=unconfined \
  --security-opt label=disable \
  -p 8188:8188 \
  -v "$(pwd)"/storage:/root \
  -e CLI_ARGS="" \
  yanwk/comfyui-boot:rocm
----

.使用 Podman
[source,sh]
----
git clone https://github.com/YanWenKun/ComfyUI-Docker.git

cd ComfyUI-Docker/rocm

podman build . -t yanwk/comfyui-boot:rocm

mkdir -p storage

podman run -it --rm \
  --name comfyui-rocm \
  --device=/dev/kfd --device=/dev/dri \
  --group-add=video --ipc=host --cap-add=SYS_PTRACE \
  --security-opt seccomp=unconfined \
  --security-opt label=disable \
  -p 8188:8188 \
  -v "$(pwd)"/storage:/root \
  -e CLI_ARGS="" \
  yanwk/comfyui-boot:rocm
----

启动完成后，访问 http://localhost:8188/

[[hint]]
## 如果你愿意折腾……

（以下内容介绍另外的安装使用方式，与本镜像无关）

ROCm 有一个 PyTorch 镜像：

https://hub.docker.com/r/rocm/pytorch

[source,sh]
----
docker pull rocm/pytorch:rocm6.2.3_ubuntu22.04_py3.10_pytorch_release_2.3.0

mkdir -p storage

docker run -it --rm \
  --name comfyui-rocm \
  --device=/dev/kfd --device=/dev/dri \
  --group-add=video --ipc=host --cap-add=SYS_PTRACE \
  --security-opt seccomp=unconfined \
  --security-opt label=disable \
  -p 8188:8188 \
  --user root \
  --workdir /root/workdir \
  -v "$(pwd)"/storage:/root/workdir \
  rocm/pytorch:rocm6.2.3_ubuntu22.04_py3.10_pytorch_release_2.3.0 \
  /bin/bash

git clone https://github.com/comfyanonymous/ComfyUI.git

# Or use conda
pip install -r ComfyUI/requirements.txt

# Or python3
python ComfyUI/main.py --listen --port 8188
----

这个镜像很大，但如果你运行遇到困难，可以尝试用这个镜像手动安装运行 ComfyUI。
它已经安装好了最重要的 PyTorch，你只需要再安装少量 Python 包即可运行 ComfyUI。

## 备注： Windows 用户

（以下内容介绍另外的安装使用方式，与本镜像无关）

WSL2 支持 ROCm 与 DirectML。

* ROCm

如果你的 AMD GPU 在
https://rocm.docs.amd.com/projects/radeon/en/latest/docs/compatibility/wsl/wsl_compatibility.html[兼容性列表]
中，你可以在 WSL2 环境中安装
https://rocm.docs.amd.com/projects/radeon/en/latest/docs/install/wsl/install-radeon.html[Radeon software]
，也可以通过 Docker Desktop 使用
<<hint, ROCm PyTorch 镜像>>。

* DirectML

DirectML 支持大多数 GPU（包括 AMD APU 与 Intel GPU）。
该方法比纯 CPU 快，比 Linux 下的 ROCm 慢，且支持的 GPU 型号更多（甚至核显也能跑）。

见：
link:../docs/wsl-directml.zh.adoc[在 WSL2 环境下通过 DirectML 运行 ComfyUI]。

* ZLUDA

这里 ZLUDA 不是跑在 WSL2 上，而是 Windows 原生运行。ZLUDA 能“翻译”CUDA 指令给 AMD GPU 运行。
这里不写详细了，因为老方法很可能一更新就不能用了，还请搜索教程。
但还是提一点建议，先试着跑 SD-WebUI，这个起手要容易不少。
